{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting ad click-through rates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We all have encountered online ads in various formats while visiting some websites. This is a big industry where people always spend a lot of their money in order to increase their sells ofcourse.\n",
    "\n",
    "Although what matters to us is that it is one of the fields that is using machine learning extensively. Our job here is to target the ads in a good manner so that maximise the click-through rate.\n",
    "\n",
    "Now, click through rate is ratio of clicks on an ad to its total number of views. Pretty straightforward. So lets jump in and lets see how we can achieve that.\n",
    "\n",
    "To study various techniques related to this application, we are going to use data from a kaggle competition(avazu) which is relatively large dataset sp we are going to use first 300,000 rows in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>...</th>\n",
       "      <th>device_type</th>\n",
       "      <th>device_conn_type</th>\n",
       "      <th>C14</th>\n",
       "      <th>C15</th>\n",
       "      <th>C16</th>\n",
       "      <th>C17</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000009e+18</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000017e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000037e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15704</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000064e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15706</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>1722</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000068e+19</td>\n",
       "      <td>0</td>\n",
       "      <td>14102100</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>fe8cc448</td>\n",
       "      <td>9166c161</td>\n",
       "      <td>0569f928</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18993</td>\n",
       "      <td>320</td>\n",
       "      <td>50</td>\n",
       "      <td>2161</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id  click      hour    C1  banner_pos   site_id site_domain  \\\n",
       "0  1.000009e+18      0  14102100  1005           0  1fbe01fe    f3845767   \n",
       "1  1.000017e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n",
       "2  1.000037e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n",
       "3  1.000064e+19      0  14102100  1005           0  1fbe01fe    f3845767   \n",
       "4  1.000068e+19      0  14102100  1005           1  fe8cc448    9166c161   \n",
       "\n",
       "  site_category    app_id app_domain ...  device_type device_conn_type    C14  \\\n",
       "0      28905ebd  ecad2386   7801e8d9 ...            1                2  15706   \n",
       "1      28905ebd  ecad2386   7801e8d9 ...            1                0  15704   \n",
       "2      28905ebd  ecad2386   7801e8d9 ...            1                0  15704   \n",
       "3      28905ebd  ecad2386   7801e8d9 ...            1                0  15706   \n",
       "4      0569f928  ecad2386   7801e8d9 ...            1                0  18993   \n",
       "\n",
       "   C15  C16   C17  C18  C19     C20  C21  \n",
       "0  320   50  1722    0   35      -1   79  \n",
       "1  320   50  1722    0   35  100084   79  \n",
       "2  320   50  1722    0   35  100084   79  \n",
       "3  320   50  1722    0   35  100084   79  \n",
       "4  320   50  2161    0   35      -1  157  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "n_rows = 300000\n",
    "df = pd.read_csv(\"train.gz\", nrows=n_rows)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['click', 'id', 'hour', 'device_id', 'device_ip'], axis=1).values\n",
    "Y = df['click'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(300000, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Validation sets\n",
    "\n",
    "Normally, we would want to split our data in train and validation sets randomly selecting rows. However, here our data is stored in chornological order as hour column is given. It wont make sense to predict past values from future data. So, we will just take first 90% of the data as training set and other 10% as validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train = int(n_rows * 0.9)\n",
    "X_train = X[:n_train]\n",
    "Y_train = Y[:n_train]\n",
    "X_test = X[n_train:]\n",
    "Y_test = Y[n_train:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding\n",
    "\n",
    "Now, we will use one hot encoding to convert our variables that are stored as strings into numerical one hot encoded values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "X_train_enc = enc.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 2)\t1.0\n",
      "  (0, 6)\t1.0\n",
      "  (0, 188)\t1.0\n",
      "  (0, 2608)\t1.0\n",
      "  (0, 2679)\t1.0\n",
      "  (0, 3771)\t1.0\n",
      "  (0, 3885)\t1.0\n",
      "  (0, 3929)\t1.0\n",
      "  (0, 4879)\t1.0\n",
      "  (0, 7315)\t1.0\n",
      "  (0, 7319)\t1.0\n",
      "  (0, 7475)\t1.0\n",
      "  (0, 7824)\t1.0\n",
      "  (0, 7828)\t1.0\n",
      "  (0, 7869)\t1.0\n",
      "  (0, 7977)\t1.0\n",
      "  (0, 7982)\t1.0\n",
      "  (0, 8021)\t1.0\n",
      "  (0, 8189)\t1.0\n"
     ]
    }
   ],
   "source": [
    "X_train_enc[0]\n",
    "print(X_train_enc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_enc = enc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding the best model\n",
    "\n",
    "Its time to train our model on our dataset. We are using tree based methods here and decision tree clasifier at that. Scikit-learn has very good implementation for this type of model and we are going to use it. Then again, to find the  best set of hyperparameters, we are going to use grid search as always with AUC-ROC as our classification metric as our classes are highly imbalanced as only 17% of clicks are positive.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 10}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "parameters = {'max_depth': [3, 10, None]}\n",
    "decision_tree = DecisionTreeClassifier(criterion='gini', min_samples_split=30)\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "grid_search = GridSearchCV(decision_tree, parameters, n_jobs=-1, cv=3, scoring='roc_auc')\n",
    "\n",
    "grid_search.fit(X_train_enc, Y_train)\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After finding the best model, we will just use the model and start predicting with it using the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree_best = grid_search.best_estimator_\n",
    "pos_prob = decision_tree_best.predict_proba(X_test_enc)[:, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.719\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('The ROC AUC on testing set is: {0:.3f}'.format(roc_auc_score(Y_test, pos_prob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "pos_prob = np.zeros(len(Y_test))\n",
    "click_index = np.random.choice(len(Y_test), int(len(Y_test) *  51211.0/300000), replace=False)\n",
    "pos_prob[click_index] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The ROC AUC on testing set is: 0.502\n"
     ]
    }
   ],
   "source": [
    "print('The ROC AUC on testing set is: {0:.3f}'.format(roc_auc_score(Y_test, pos_prob)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classfier\n",
    "\n",
    "We have tried decision tree classifier and accuracy was 0.72 which is not so good but as CTR depends on many other factors than those that are provided to us. This is considered a good score apparently. To compare, we built a random genrator using numpy and it turned out to be 0.5 auc-roc score which is making our score looks good i guess.\n",
    "\n",
    "Enough with decsion tree, we will move on to random forest classifier and doing the same steps, will try to find out what are the scores this model will give us\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100, criterion='gini', min_samples_split=30, n_jobs=-1)\n",
    "grid_search = GridSearchCV(random_forest, parameters, n_jobs=-1, cv=3, scoring='roc_auc')\n",
    "grid_search.fit(X_train_enc, Y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "\n",
    "random_forest_best = grid_search.best_estimator_\n",
    "pos_prob = random_forest_best.predict_proba(X_test_enc)[:, 1]\n",
    "print('The ROC AUC on testing set is: {0:.3f}'.format(roc_auc_score(Y_test, pos_prob)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using random forest classifier, we are getting a score of 0.76 which is a good improvement over decision tree. We can use other algoriths like lightGBM or xgBoost to get even higher scores which are all available in scikit learn and can be implemented similarly.\n",
    "\n",
    "\n",
    "Some things abouts hyperparamters:\n",
    "1. \"criterion = gini\" relates to how decision tree are implemented in scikit learn. There are other imlememtations too and we are using gini among them\n",
    "2. n_jobs = -1 suggests that we are using all CPU processors for our task.\n",
    "3. n_estimators = 100  tells our model how many trees are there in out random forest.\n",
    "4. parameters. How much deep is our tree? How many leaves that is.\n",
    "5. min_samples_split = 30. Minimum number of samples required to split an internal node. Refers to how new leaves are made.\n",
    "6. class_weights . How much weight is given to a class while predicting?\n",
    "\n",
    "Grid_Search Parameters:\n",
    "1. FIrst is name of our model.\n",
    "2. Parameters providing which values for certain parameters should be tested in finding best model. Here, i only took depth as parameter but we can also use min_sample_split and class_weight to test for their best values.\n",
    "3. n_jobs again.\n",
    "4. cv = 3. Cross validation.\n",
    "5. Scoring . What type of metric to use for scoring purposes.\n",
    "\n",
    "\n",
    "\n",
    "So, that was all about using tree based methods for AD click prediction. Now, we have to remember that there are other models that can give better results like LGBM and xgBoost and we can use them and everyone is using them as well to get best results. But let us say you know all the algorithms and using best algorithms always. What then?\n",
    "\n",
    "The main thing we always  have at our disposal is our logic and how we use it to genrate and select features in our model. It can be very much possible that naive algorithms like logistic regression can give better performance than ensemble algorithms like xgBoost. So, lets keep that in mind and spend more time on understanding the data than to choose the best algorithms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
